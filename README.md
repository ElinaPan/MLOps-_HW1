
# MLOps HW1 — воспроизводимый ML-пайплайн с DVC и MLflow

Автор: **Panagiotou Elina**

## Цель проекта

Цель проекта — построить минимальный, но полноценный MLOps-контур для задачи классификации:

- обеспечить **воспроизводимость экспериментов**;
- настроить **версионирование данных** через DVC;
- автоматизировать процесс подготовки данных и обучения модели с помощью **DVC-пайплайна**;
- логировать **гиперпараметры, метрики и артефакты модели** в MLflow;
- запускать всё обучение одной командой `dvc repro`.

Проект использует небольшой классический датасет **Iris** (многоклассовая классификация трёх видов ирисов) и модель **логистической регрессии**.


## Описание датасета

В качестве демонстрационного датасета используется **Iris** (из библиотеки `scikit-learn`):

- 150 объектов (цветы ириса),
- 4 числовых признака:
  - sepal length (cm) — длина чашелистика,
  - sepal width (cm) — ширина чашелистика,
  - petal length (cm) — длина лепестка,
  - petal width (cm) — ширина лепестка,
- целевая переменная `target` — вид ириса: *setosa*, *versicolor*, *virginica* (3 класса).

Датасет небольшой, чистый и стандартизованный, поэтому хорошо подходит для учебной задачи по построению воспроизводимого ML-пайплайна и демонстрации работы DVC и MLflow.



## Структура проекта

\`\`\`text
.
├── data/
│   ├── raw/           # сырые данные (data.csv) — под управлением DVC
│   └── processed/     # подготовленные данные (train/test)
├── src/
│   ├── prepare.py     # подготовка данных: сплит, базовая очистка
│   └── train.py       # обучение модели и логирование в MLflow
├── dvc.yaml           # описание DVC-пайплайна (stages: prepare, train)
├── dvc.lock           # зафиксированные версии данных/артефактов для воспроизводимости
├── params.yaml        # гиперпараметры (сплит, модель и т.д.)
├── requirements.txt   # список зависимостей
└── README.md          # документация (текущий файл)
\`\`\`


## Как запустить проект

1. Клонировать репозиторий:

\`\`\`bash
git clone <URL_репозитория>
cd <имя_папки_проекта>
\`\`\`

2. Установить зависимости:

\`\`\`bash
pip install -r requirements.txt
\`\`\`

3. Подтянуть данные, версионируемые через DVC:

\`\`\`bash
dvc pull
\`\`\`

4. Воспроизвести ML-пайплайн:

\`\`\`bash
dvc repro
\`\`\`

Результат:
- сгенерируются train/test файлы в `data/processed/`,
- обучится модель (`model.pkl`),
- параметры, метрики и артефакты появятся в MLflow.


## Работа с MLflow (Tracking UI)

Запуск интерфейса:

\`\`\`bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
\`\`\`

Открыть в браузере:

\`\`\`
http://127.0.0.1:5000
\`\`\`

MLflow логирует:
- параметры модели,
- гиперпараметры,
- accuracy,
- файл модели (`model.pkl`).


## DVC-пайплайн

### Stage 1: **prepare**

- читает `data/raw/data.csv`
- делит на train/test
- сохраняет в `data/processed/`

### Stage 2: **train**

- читает train/test
- обучает логистическую регрессию
- считает accuracy
- сохраняет `model.pkl`
- логирует параметры/метрики в MLflow


## Версионирование данных через DVC

- `data/raw/data.csv` добавлен через `dvc add`
- данные не хранятся в Git
- вместо этого используется:
  - `data/raw/data.csv.dvc`
  - `.gitignore`
  - локальное DVC-хранилище или удалённый remote

Команда для подтягивания данных:

\`\`\`bash
dvc pull
\`\`\`


## Итог

Проект демонстрирует полный цикл минимального MLOps-контура:

- управление данными (DVC),
- управление пайплайном (DVC),
- воспроизводимость (dvc repro + dvc.lock),
- логирование экспериментов (MLflow),
- обучение модели одной командой.

Готов для сдачи ДЗ.
